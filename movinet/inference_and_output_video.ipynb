{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow==2.15.0\n",
    "%pip install tf-models-official==2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from keras import layers, models\n",
    "import tensorflow.keras as keras\n",
    "import os\n",
    "from official.projects.movinet.modeling import movinet\n",
    "from official.projects.movinet.modeling import movinet_model\n",
    "# from tf.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import datetime\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WSL_PATH = './DL2/project/movinet'\n",
    "print(os.cwd())\n",
    "print(os.path.isdir(WSL_PATH))\n",
    "\n",
    "\n",
    "video_name     = 'recorded_video.mp4'\n",
    "inf_video_name = 'inference_video.mp4'\n",
    "model_name     = 'trained_checkpoints-a4-10epoch-30numofframes8batchsize20240325-151003'\n",
    "\n",
    "model_path     = os.path.join(WSL_PATH, 'models', model_name)\n",
    "video_path     = os.path.join(WSL_PATH, 'videos', video_name)\n",
    "inf_video_path = os.path.join(WSL_PATH, 'videos', inf_video_name)\n",
    "class_names    = ['bird', 'boar', 'dog', 'dragon', 'horse', 'monkey', 'ox', 'rabbit', 'rat', 'sheep', 'snake', 'tiger']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess video frames\n",
    "def preprocess_frame(frame, size=(224,224)):\n",
    "    # Resize frame to 172x172\n",
    "    frame = cv2.resize(frame, size)\n",
    "    # Normalize pixel values to be between 0 and 1\n",
    "    frame = frame / 255.0\n",
    "    # Expand dimensions to match model's input\n",
    "    frame = np.expand_dims(frame, axis=0)\n",
    "    return frame\n",
    "\n",
    "def process_batch(batch, model):\n",
    "    batch = np.array(batch)  # Convert list to numpy array\n",
    "    predictions = model(batch)\n",
    "    return predictions\n",
    "\n",
    "def predict_video(video_path, model, size=(224,224)):\n",
    "  \"\"\"\n",
    "  Display video frames with class names.\n",
    "\n",
    "  Args:\n",
    "    video_path (str): Path to the video file.\n",
    "    model (list): List of video frames.\n",
    "    size (list): size of the model input, which will be used to resize the frame\n",
    "  \"\"\"\n",
    "  print(os.path.isfile(video_path))\n",
    "  print(video_path)\n",
    "  \n",
    "  cap = cv2.VideoCapture(video_path)\n",
    "  frame_count = 0\n",
    "  frames = 30\n",
    "  frames_batch = []\n",
    "  all_predictions = []\n",
    "  predictions_results = []\n",
    "  frames_arr = []\n",
    "\n",
    "  while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    frame_count += 1\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    preprocessed_frame = preprocess_frame(frame)\n",
    "    frames_arr.append(frame)\n",
    "    frames_batch.append(preprocessed_frame)\n",
    "\n",
    "    # # If batch is full, process the batch, ignoreing the rest of the frame if not full batch\n",
    "    if len(frames_batch) == frames:\n",
    "        predictions = process_batch(frames_batch, model)\n",
    "        all_predictions.append(predictions)\n",
    "        \n",
    "        # Get class name of top predicted class\n",
    "        predicted_indices = tf.argmax(predictions, axis=1)\n",
    "        predicted_class_names = [class_names[i] for i in predicted_indices.numpy()]\n",
    "        predictions_results.append(predicted_class_names)\n",
    "        frames_batch = []  # Reset the batch\n",
    "\n",
    "  cap.release()\n",
    "  predictions_results = np.array(predictions_results).flatten()\n",
    "  \n",
    "  print(f\"Processed {len(all_predictions)} batches.\")\n",
    "  print(f\"Total frames {frame_count}\")\n",
    "  # print(f\"Result: {predictions_results}\")\n",
    "  # print(f\"Counts: {len(predictions_results)}\")\n",
    "  \n",
    "  return predictions_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 15:41:54.285864: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-25 15:41:54.441980: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-25 15:41:54.442017: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-25 15:41:54.446519: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-25 15:41:54.446579: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-25 15:41:54.446633: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-25 15:41:54.668241: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-25 15:41:54.668287: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-25 15:41:54.668292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-25 15:41:54.668315: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-25 15:41:54.668331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f3a9c1f0160>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "# model = load_weights(model_path)\n",
    "def build_classifier(batch_size, num_frames, resolution, backbone, num_classes):\n",
    "    \"\"\"Builds a classifier on top of a backbone model.\"\"\"\n",
    "    model = movinet_model.MovinetClassifier(\n",
    "        backbone=backbone,\n",
    "        num_classes=num_classes)\n",
    "    model.build([batch_size, num_frames, resolution, resolution, 3])\n",
    "\n",
    "    return model\n",
    "\n",
    "num_frames = 30\n",
    "resolution = 320\n",
    "batch_size = 8\n",
    "model_id = 'a4'\n",
    "backbone = movinet.Movinet(model_id=model_id)\n",
    "backbone.trainable = False\n",
    "model = build_classifier(batch_size, num_frames, resolution, backbone, 12)\n",
    "weights_path = model_path\n",
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform prediction\n",
    "predictions_results = predict_video(video_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video_with_class_names(video_path, class_names):\n",
    "    \"\"\"\n",
    "    Display video frames with class names.\n",
    "\n",
    "    Args:\n",
    "        video_path (list): Path of video.\n",
    "        class_names (list): List of class names corresponding to each frame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # name = inf_video_name + '.mp4'\n",
    "    # fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "    frame_count = 0\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    out = cv2.VideoWriter(inf_video_path, fourcc, 20.0, ((width, height)))\n",
    "    if not out.isOpened():\n",
    "      print(\"Error: Could not open output video for writing.\")\n",
    "      return\n",
    "    \n",
    "    while cap.isOpened():\n",
    "      ret, frame = cap.read()\n",
    "      if not ret:\n",
    "          break\n",
    "\n",
    "      if len(class_names) > frame_count:\n",
    "        frame_with_text = frame.copy()\n",
    "        cv2.rectangle(frame_with_text, (10, 10), (200, 40), (255, 255, 255), -1)  # Rectangle background\n",
    "        cv2.putText(frame_with_text, class_names[frame_count], (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)  # Class name text\n",
    "        # frame_with_text_uint8 = frame_with_text.astype(np.uint8)\n",
    "        out.write(frame_with_text)\n",
    "      frame_count += 1\n",
    "\n",
    "    out.release()\n",
    "    cap.release()\n",
    "\n",
    "# Combine to video\n",
    "save_video_with_class_names(video_path, predictions_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
