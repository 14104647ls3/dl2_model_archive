{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()  # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_example(image, label):\n",
    "    feature = {\n",
    "        'image': _bytes_feature(image),\n",
    "        'label': _int64_feature(label),\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "\n",
    "def split_data(video_paths, labels, train_ratio=0.8):\n",
    "    \"\"\"Split the data into training and testing sets.\"\"\"\n",
    "    # Shuffle the data first (make sure to shuffle video_paths and labels in unison)\n",
    "    combined = list(zip(video_paths, labels))\n",
    "    random.shuffle(combined)\n",
    "    video_paths[:], labels[:] = zip(*combined)\n",
    "    \n",
    "    # Split the data\n",
    "    total_videos = len(video_paths)\n",
    "    train_size = int(total_videos * train_ratio)\n",
    "    \n",
    "    train_video_paths = video_paths[:train_size]\n",
    "    train_labels = labels[:train_size]\n",
    "    \n",
    "    test_video_paths = video_paths[train_size:]\n",
    "    test_labels = labels[train_size:]\n",
    "    \n",
    "    return (train_video_paths, train_labels), (test_video_paths, test_labels)\n",
    "\n",
    "def video_to_tfrecord(video_paths, labels, tfrecord_file):\n",
    "    with tf.io.TFRecordWriter(tfrecord_file) as writer:\n",
    "        for video_path, label in zip(video_paths, labels):\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            success, frame = cap.read()\n",
    "            while success:\n",
    "                # Normalize pixel values to be between 0 and 1\n",
    "                frame = frame.astype(np.float32) / 255.0\n",
    "                _, buffer = cv2.imencode('.jpg', frame * 255)  # Convert back to byte format\n",
    "                example = serialize_example(buffer.tobytes(), label)\n",
    "                writer.write(example)\n",
    "                success, frame = cap.read()\n",
    "            cap.release()\n",
    "\n",
    "def create_dataset(source_dir, train_tfrecord_file, test_tfrecord_file, train_ratio=0.8):\n",
    "    classes = os.listdir(source_dir)\n",
    "    class_labels = {class_name: i for i, class_name in enumerate(classes)}\n",
    "    \n",
    "    video_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_name, class_label in class_labels.items():\n",
    "        class_dir = os.path.join(source_dir, class_name)\n",
    "        if os.path.isfile(class_dir):\n",
    "            continue\n",
    "        for video_name in os.listdir(class_dir):\n",
    "            video_path = os.path.join(class_dir, video_name)\n",
    "            if video_path.endswith('.mp4'):\n",
    "                video_paths.append(video_path)\n",
    "                labels.append(class_label)\n",
    "    \n",
    "    # Split the data into training and testing\n",
    "    (train_video_paths, train_labels), (test_video_paths, test_labels) = split_data(video_paths, labels, train_ratio)\n",
    "    \n",
    "    # Create TFRecord for training and testing datasets\n",
    "    video_to_tfrecord(train_video_paths, train_labels, train_tfrecord_file)\n",
    "    video_to_tfrecord(test_video_paths, test_labels, test_tfrecord_file)\n",
    "\n",
    "# Example usage\n",
    "WSL_PATH = './project/movinet'\n",
    "TRAIN_DATASET_NAME = os.path.join(WSL_PATH,'videov3_train_dataset.tfrecord')\n",
    "TEST_DATASET_NAME = os.path.join(WSL_PATH,'videov3_test_dataset.tfrecord')\n",
    "source_dir = os.path.join(WSL_PATH, 'videos_v3')\n",
    "create_dataset(source_dir, TRAIN_DATASET_NAME, TEST_DATASET_NAME, train_ratio=0.8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
